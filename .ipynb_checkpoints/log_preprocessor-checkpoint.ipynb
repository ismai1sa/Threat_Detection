{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6a5b3e0-86e3-4d58-bd74-45b8eb14ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] All logs cleaned, normalized, and saved to final_normalized_logs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93552/3629000890.py:127: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_dataset = pd.concat(dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Corrected: removed duplicate 'dest_domain'\n",
    "REQUIRED_COLUMNS = [\n",
    "    'timestamp', 'user', 'action', 'description', 'protocol', 'url', 'method',\n",
    "    'source_ip', 'dest_ip', 'dest_domain', 'client_ip', 'source_port',\n",
    "    'dest_port', 'severity', 'host', 'rule_name', 'app', 'category',\n",
    "    'bytes_sent', 'bytes_received', 'threat_id', 'user_agent', 'eventid',\n",
    "    'workstation', 'privilege', 'object', 'accessmask', 'target', 'status',\n",
    "    'reason', 'process', 'parentprocess', 'fileaccessed', 'alert', 'machine',\n",
    "    'os', 'details', 'resource', 'hostname', 'location', 'facility', 'code',\n",
    "    'message', 'event', 'file', 'verdict', 'log_type'\n",
    "]\n",
    "\n",
    "def clean_csv_log(file_path, log_type):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        df.dropna(how='all', inplace=True)\n",
    "        df.columns = [col.strip().lower().replace(' ', '_') for col in df.columns]\n",
    "        df['log_type'] = log_type\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error reading {file_path}: {e}\")\n",
    "        return pd.DataFrame(columns=REQUIRED_COLUMNS)\n",
    "\n",
    "def normalize_timestamp(ts):\n",
    "    try:\n",
    "        return datetime.strptime(ts, '%Y-%m-%d %H:%M:%S').isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def clean_ip_column(ip):\n",
    "    ip_pattern = r'^(\\d{1,3}\\.){3}\\d{1,3}$'\n",
    "    if isinstance(ip, str) and re.match(ip_pattern, ip):\n",
    "        return ip\n",
    "    return np.nan\n",
    "\n",
    "def clean_domain_column(domain):\n",
    "    domain_pattern = r'^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    if isinstance(domain, str) and re.match(domain_pattern, domain):\n",
    "        return domain.lower()\n",
    "    return np.nan\n",
    "\n",
    "def map_ad_columns(df):\n",
    "    ip_fields = ['client_ip', 'client_address', 'ip_address', 'ip']\n",
    "    client_ip_col = next((col for col in ip_fields if col in df.columns), None)\n",
    "    \n",
    "    if client_ip_col:\n",
    "        df['client_ip'] = df[client_ip_col]\n",
    "    else:\n",
    "        df['client_ip'] = None\n",
    "\n",
    "    col_map = {\n",
    "        'user': 'user',\n",
    "        'description': 'description',\n",
    "        'timestamp': 'timestamp'\n",
    "    }\n",
    "    col_map = {k: v for k, v in col_map.items() if k in df.columns}\n",
    "    df = df.rename(columns=col_map)\n",
    "    return df\n",
    "\n",
    "def map_proxy_columns(df):\n",
    "    ip_fields = ['client', 'client_ip', 'source_ip', 'ip']\n",
    "    for field in ip_fields:\n",
    "        if field in df.columns:\n",
    "            df['client_ip'] = df[field].astype(str).str.extract(r'(\\d{1,3}(?:\\.\\d{1,3}){3})')[0]\n",
    "            break\n",
    "    else:\n",
    "        df['client_ip'] = None\n",
    "\n",
    "    if 'url' in df.columns:\n",
    "        df['hostname'] = df['url'].apply(lambda x: urlparse(str(x)).hostname if pd.notnull(x) else None)\n",
    "\n",
    "    return df\n",
    "\n",
    "def map_firewall_columns(df):\n",
    "    if 'dest_ip' in df.columns:\n",
    "        df['dest_domain'] = df['dest_ip'].apply(\n",
    "            lambda x: x if isinstance(x, str) and not re.match(r'^(\\d{1,3}\\.){3}\\d{1,3}$', x) else np.nan\n",
    "        )\n",
    "        df['dest_ip'] = df['dest_ip'].apply(clean_ip_column)\n",
    "    return df\n",
    "\n",
    "# Define your input files\n",
    "log_files = {\n",
    "    \"firewall\": \"./logs/firewall_logs.csv\",\n",
    "    \"proxy\": \"./logs/proxy3_logs.csv\",\n",
    "    \"ad\": \"./logs/ad_logs.csv\",\n",
    "    \"edr\": \"./logs/edr_logs.csv\",\n",
    "    \"iam\": \"./logs/iam_logs.csv\",\n",
    "    \"mail\": \"./logs/mail2_logs.csv\",\n",
    "    \"router\": \"./logs/router_logs.csv\",\n",
    "    \"user\": \"./logs/user.csv\",\n",
    "    \"siem\": \"./logs/siem_logs.csv\"\n",
    "}\n",
    "\n",
    "dataframes = []\n",
    "for log_type, file_path in log_files.items():\n",
    "    df = clean_csv_log(file_path, log_type)\n",
    "\n",
    "    if df.empty:\n",
    "        continue\n",
    "\n",
    "    if log_type == 'ad':\n",
    "        df = map_ad_columns(df)\n",
    "    elif log_type == 'proxy':\n",
    "        df = map_proxy_columns(df)\n",
    "    elif log_type == 'firewall':\n",
    "        df = map_firewall_columns(df)\n",
    "    else:\n",
    "        df['client_ip'] = None\n",
    "        df['dest_domain'] = None\n",
    "\n",
    "    # Ensure all required columns exist\n",
    "    for col in REQUIRED_COLUMNS:\n",
    "        if col not in df.columns:\n",
    "            df[col] = None\n",
    "\n",
    "    df = df[REQUIRED_COLUMNS]  # Reorder and limit columns\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all processed logs\n",
    "final_dataset = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Normalize timestamps\n",
    "final_dataset['timestamp'] = final_dataset['timestamp'].apply(normalize_timestamp)\n",
    "\n",
    "# Clean IP fields\n",
    "for ip_col in ['source_ip', 'dest_ip', 'client_ip']:\n",
    "    final_dataset[ip_col] = final_dataset[ip_col].apply(clean_ip_column)\n",
    "\n",
    "# Clean domain fields\n",
    "final_dataset['domain'] = final_dataset['hostname'].apply(clean_domain_column)\n",
    "final_dataset['dest_domain'] = final_dataset['dest_domain'].apply(clean_domain_column)\n",
    "\n",
    "# Drop temporary hostname column\n",
    "final_dataset.drop(columns=['hostname'], inplace=True)\n",
    "\n",
    "# Save final output\n",
    "final_dataset.to_csv(\"final_normalized_logs.csv\", index=False)\n",
    "print(\"[✓] All logs cleaned, normalized, and saved to final_normalized_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af62aa1-17d3-4d88-80e3-5204bb4fb96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned and organized log saved as 'final_logs_cleaned_and_organized.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"final_normalized_logs.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# Drop fully empty rows and columns\n",
    "df.dropna(how='all', inplace=True)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Clean string fields (except some text fields)\n",
    "exclude_clean = ['user_agent', 'url', 'fileaccessed', 'message']\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    if col not in exclude_clean:\n",
    "        df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Convert and clean timestamp\n",
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    df = df[df['timestamp'].notna()]\n",
    "\n",
    "# Clean and standardize event ID fields\n",
    "for field in ['eventid', 'threat_id']:\n",
    "    if field in df.columns:\n",
    "        df[field] = df[field].replace(['', ' ', 'nan', 'None', None], pd.NA).fillna(-1)\n",
    "        try:\n",
    "            df[field] = df[field].astype(int)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "# IP fields cleanup\n",
    "ip_fields = ['source_ip', 'dest_ip', 'client_ip']\n",
    "for col in ip_fields:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.extract(r'(\\d{1,3}(?:\\.\\d{1,3}){3})')[0].fillna('0.0.0.0')\n",
    "\n",
    "# Port cleanup: convert to int, replace 0 with -1\n",
    "for port in ['source_port', 'dest_port']:\n",
    "    if port in df.columns:\n",
    "        df[port] = pd.to_numeric(df[port], errors='coerce').fillna(0).astype(int)\n",
    "        df[port] = df[port].replace(0, -1)\n",
    "\n",
    "# Clean bytes sent/received\n",
    "for col in ['bytes_sent', 'bytes_received']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Normalize categorical fields\n",
    "cat_fields = ['action', 'severity', 'verdict', 'log_type', 'category', 'protocol']\n",
    "for col in cat_fields:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].replace({'none': np.nan, 'na': np.nan, 'null': np.nan}).fillna('unknown')\n",
    "\n",
    "# Fill general missing values with defaults\n",
    "df.fillna({\n",
    "    'user': 'unknown',\n",
    "    'app': 'unknown',\n",
    "    'rule_name': 'unknown',\n",
    "    'host': 'unknown',\n",
    "    'workstation': 'unknown',\n",
    "    'privilege': 'unknown',\n",
    "    'event': 'unknown',\n",
    "    'status': 'unknown',\n",
    "    'alert': 'none',\n",
    "    'machine': 'unknown',\n",
    "    'os': 'unknown',\n",
    "    'domain': 'unknown',\n",
    "    'location': 'unknown',\n",
    "    'reason': 'unspecified',\n",
    "    'accessmask': 'unknown',\n",
    "}, inplace=True)\n",
    "\n",
    "# Fill specific content/logging fields\n",
    "text_fill = {\n",
    "    'url': 'unknown_url',\n",
    "    'user_agent': 'unknown_agent',\n",
    "    'fileaccessed': 'none',\n",
    "    'message': 'no_message',\n",
    "}\n",
    "for col, default in text_fill.items():\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(default).replace('nan', default).replace('', default)\n",
    "\n",
    "# Reorder columns for readability\n",
    "preferred_order = [\n",
    "    'timestamp', 'eventid', 'threat_id', 'user', 'severity', 'log_type',\n",
    "    'source_ip', 'source_port', 'dest_ip', 'dest_port', 'client_ip', 'dest_domain',\n",
    "    'protocol', 'action', 'verdict', 'category', 'app', 'rule_name',\n",
    "    'bytes_sent', 'bytes_received', 'url', 'method', 'user_agent',\n",
    "    'description', 'fileaccessed', 'host', 'workstation', 'privilege',\n",
    "    'object', 'accessmask', 'target', 'status', 'reason',\n",
    "    'process', 'parentprocess', 'alert', 'machine', 'os', 'event', 'file',\n",
    "    'facility', 'code', 'message', 'details', 'resource', 'location', 'domain'\n",
    "]\n",
    "existing = [col for col in preferred_order if col in df.columns]\n",
    "extra = [col for col in df.columns if col not in existing]\n",
    "df = df[existing + extra]\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"final_logs_cleaned_and_organized.csv\", index=False)\n",
    "print(\"✅ Cleaned and organized log saved as 'final_logs_cleaned_and_organized.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447aea24-441d-4979-a97b-3deed8ef916e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
